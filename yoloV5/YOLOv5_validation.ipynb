{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "little-scratch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=./yolov5/rip_detection.yaml, weights=['runs/train/yolo_v5s_pretrained_v0.2/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=val_yolo_v5s_pretrained_v0.2, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v5.0-351-ge96c74b torch 1.8.0a0+52ea372 CUDA:0 (Quadro P5000, 16278.5625MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 224 layers, 7053910 parameters, 0 gradients, 16.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label datasets/images/val/rip-1123.png: negative labels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        162        162      0.953      0.883      0.917      0.429\n",
      "Speed: 1.9ms pre-process, 6.9ms inference, 4.3ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/val_yolo_v5s_pretrained_v0.2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ./yolov5/val.py --img 640 --weights runs/train/yolo_v5s_pretrained_v0.2/weights/best.pt --data ./yolov5/rip_detection.yaml --name val_yolo_v5s_pretrained_v0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "complimentary-athletics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=./yolov5/rip_detection.yaml, weights=['runs/train/yolo_v5s_custom/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=yolo_v5s_custom, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v5.0-351-ge96c74b torch 1.8.0a0+52ea372 CUDA:0 (Quadro P5000, 16278.5625MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 224 layers, 7053910 parameters, 0 gradients, 16.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label datasets/images/val/rip-1123.png: negative labels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        162        162      0.907      0.907      0.916      0.404\n",
      "Speed: 1.4ms pre-process, 7.4ms inference, 3.2ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/yolo_v5s_custom\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ./yolov5/val.py --img 640 --weights runs/train/yolo_v5s_custom/weights/best.pt --data ./yolov5/rip_detection.yaml --name val_yolo_v5s_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alpha-balance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=./yolov5/rip_detection.yaml, weights=['runs/train/yolo_v5m_pretrained_v0.1/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=val_yolo_v5m_pretrained_v0.1, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v5.0-351-ge96c74b torch 1.8.0a0+52ea372 CUDA:0 (Quadro P5000, 16278.5625MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 308 layers, 21037638 parameters, 0 gradients, 50.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label datasets/images/val/rip-1123.png: negative labels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        162        162      0.918      0.901      0.931       0.43\n",
      "Speed: 0.3ms pre-process, 16.0ms inference, 2.7ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/val_yolo_v5m_pretrained_v0.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ./yolov5/val.py --img 640 --weights runs/train/yolo_v5m_pretrained_v0.1/weights/best.pt --data ./yolov5/rip_detection.yaml --name val_yolo_v5m_pretrained_v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "reliable-williams",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=./yolov5/rip_detection.yaml, weights=['runs/train/yolo_v5m_custom_v0.1/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=val_yolo_v5m_custom_v0.1, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v5.0-351-ge96c74b torch 1.8.0a0+52ea372 CUDA:0 (Quadro P5000, 16278.5625MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 308 layers, 21037638 parameters, 0 gradients, 50.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label datasets/images/val/rip-1123.png: negative labels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        162        162      0.913      0.907      0.932      0.441\n",
      "Speed: 0.4ms pre-process, 15.6ms inference, 2.8ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/val_yolo_v5m_custom_v0.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ./yolov5/val.py --img 640 --weights runs/train/yolo_v5m_custom_v0.1/weights/best.pt --data ./yolov5/rip_detection.yaml --name val_yolo_v5m_custom_v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beginning-blame",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=./yolov5/rip_detection.yaml, weights=['runs/train/yolo_v5l_pretrained_v03.1/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=val_yolo_v5l_pretrained_v0.1, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v5.0-351-ge96c74b torch 1.8.0a0+52ea372 CUDA:0 (Quadro P5000, 16278.5625MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 392 layers, 46600566 parameters, 0 gradients, 114.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label datasets/images/val/rip-1123.png: negative labels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        162        162      0.904      0.932      0.936      0.432\n",
      "Speed: 0.4ms pre-process, 24.7ms inference, 2.8ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/val_yolo_v5l_pretrained_v02.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ./yolov5/val.py --img 640 --weights runs/train/yolo_v5l_pretrained_v03.1/weights/best.pt --data ./yolov5/rip_detection.yaml --name val_yolo_v5l_pretrained_v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "applied-ethiopia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=./yolov5/rip_detection.yaml, weights=['runs/train/yolo_v5l_custom_v0.1/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=val_yolo_v5l_custom_v0.1, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v5.0-351-ge96c74b torch 1.8.0a0+52ea372 CUDA:0 (Quadro P5000, 16278.5625MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 392 layers, 46600566 parameters, 0 gradients, 114.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label datasets/images/val/rip-1123.png: negative labels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        162        162      0.891      0.907       0.91      0.439\n",
      "Speed: 0.5ms pre-process, 24.4ms inference, 2.6ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/val_yolo_v5l_custom_v03.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ./yolov5/val.py --img 640 --weights runs/train/yolo_v5l_custom_v0.1/weights/best.pt --data ./yolov5/rip_detection.yaml --name val_yolo_v5l_custom_v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bridal-distributor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=./yolov5/rip_detection.yaml, weights=['runs/train/yolo_v5x_pretrained_v0.1/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=val_yolo_v5x_pretrained_v0.1, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v5.0-351-ge96c74b torch 1.8.0a0+52ea372 CUDA:0 (Quadro P5000, 16278.5625MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 476 layers, 87198694 parameters, 0 gradients, 217.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label datasets/images/val/rip-1123.png: negative labels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        162        162      0.923      0.889       0.93      0.447\n",
      "Speed: 0.2ms pre-process, 42.1ms inference, 2.3ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/val_yolo_v5x_pretrained_v0.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ./yolov5/val.py --img 640 --weights runs/train/yolo_v5x_pretrained_v0.1/weights/best.pt --data ./yolov5/rip_detection.yaml --name val_yolo_v5x_pretrained_v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "threaded-circuit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=./yolov5/rip_detection.yaml, weights=['runs/train/yolo_v5x_custom_v0.1/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=val_yolo_v5x_custom_v0.1, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v5.0-351-ge96c74b torch 1.8.0a0+52ea372 CUDA:0 (Quadro P5000, 16278.5625MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 476 layers, 87198694 parameters, 0 gradients, 217.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\u001b[34m\u001b[1mval: \u001b[0mWARNING: Ignoring corrupted image and/or label datasets/images/val/rip-1123.png: negative labels\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'datasets/labels/val.cache' images and labels... 163 found, 0 miss\u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        162        162       0.93      0.907      0.922      0.448\n",
      "Speed: 0.4ms pre-process, 41.3ms inference, 2.4ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/val_yolo_v5x_custom_v0.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ./yolov5/val.py --img 640 --weights runs/train/yolo_v5x_custom_v0.1/weights/best.pt --data ./yolov5/rip_detection.yaml --name val_yolo_v5x_custom_v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "metric-diagram",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=./yolov5/rip_detection.yaml, weights=['runs/train/yolo_v5s_pretrained_v0.2/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=test_yolo_v5s_pretrained_v0.2, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v5.0-351-ge96c74b torch 1.8.0a0+52ea372 CUDA:0 (Quadro P5000, 16278.5625MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 224 layers, 7053910 parameters, 0 gradients, 16.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test' images and labels...163 found, 0 missing, \u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mWARNING: Ignoring corrupted image and/or label datasets/images/test/rip-676.png: negative labels\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: datasets/labels/test.cache\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        162        162      0.887      0.876      0.886      0.358\n",
      "Speed: 0.2ms pre-process, 7.2ms inference, 3.1ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/test_yolo_v5s_pretrained_v0.2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#### TEST\n",
    "!python ./yolov5/val.py --img 640 --task 'test' --weights runs/train/yolo_v5s_pretrained_v0.2/weights/best.pt --data ./yolov5/rip_detection.yaml --name test_yolo_v5s_pretrained_v0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "distributed-beauty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=./yolov5/rip_detection.yaml, weights=['runs/train/yolo_v5s_custom/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=test_yolo_v5s_custom, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v5.0-351-ge96c74b torch 1.8.0a0+52ea372 CUDA:0 (Quadro P5000, 16278.5625MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 224 layers, 7053910 parameters, 0 gradients, 16.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\u001b[34m\u001b[1mtest: \u001b[0mWARNING: Ignoring corrupted image and/or label datasets/images/test/rip-676.png: negative labels\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        162        162      0.846      0.919      0.898      0.341\n",
      "Speed: 0.2ms pre-process, 8.8ms inference, 2.6ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/test_yolo_v5s_custom\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ./yolov5/val.py --img 640 --task 'test' --weights runs/train/yolo_v5s_custom/weights/best.pt --data ./yolov5/rip_detection.yaml --name test_yolo_v5s_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "piano-standard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=./yolov5/rip_detection.yaml, weights=['runs/train/yolo_v5m_pretrained_v0.1/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=test_yolo_v5m_pretrained_v0.1, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v5.0-351-ge96c74b torch 1.8.0a0+52ea372 CUDA:0 (Quadro P5000, 16278.5625MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 308 layers, 21037638 parameters, 0 gradients, 50.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\u001b[34m\u001b[1mtest: \u001b[0mWARNING: Ignoring corrupted image and/or label datasets/images/test/rip-676.png: negative labels\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        162        162      0.836      0.883      0.859      0.333\n",
      "Speed: 0.2ms pre-process, 15.5ms inference, 1.7ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/test_yolo_v5m_pretrained_v0.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ./yolov5/val.py --img 640 --task 'test' --weights runs/train/yolo_v5m_pretrained_v0.1/weights/best.pt --data ./yolov5/rip_detection.yaml --name test_yolo_v5m_pretrained_v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "rolled-thought",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=./yolov5/rip_detection.yaml, weights=['runs/train/yolo_v5m_custom_v0.1/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=test_yolo_v5m_custom_v0.1, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v5.0-351-ge96c74b torch 1.8.0a0+52ea372 CUDA:0 (Quadro P5000, 16278.5625MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 308 layers, 21037638 parameters, 0 gradients, 50.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\u001b[34m\u001b[1mtest: \u001b[0mWARNING: Ignoring corrupted image and/or label datasets/images/test/rip-676.png: negative labels\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        162        162      0.917      0.883      0.898      0.362\n",
      "Speed: 0.2ms pre-process, 14.6ms inference, 2.4ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/test_yolo_v5m_custom_v0.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ./yolov5/val.py --img 640 --task 'test' --weights runs/train/yolo_v5m_custom_v0.1/weights/best.pt --data ./yolov5/rip_detection.yaml --name test_yolo_v5m_custom_v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "active-engineer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=./yolov5/rip_detection.yaml, weights=['runs/train/yolo_v5l_pretrained_v03.1/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=test_yolo_v5l_pretrained_v0.1, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v5.0-351-ge96c74b torch 1.8.0a0+52ea372 CUDA:0 (Quadro P5000, 16278.5625MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 392 layers, 46600566 parameters, 0 gradients, 114.1 GFLOPs\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\u001b[34m\u001b[1mtest: \u001b[0mWARNING: Ignoring corrupted image and/or label datasets/images/test/rip-676.png: negative labels\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        162        162      0.914      0.858      0.917      0.357\n",
      "Speed: 0.2ms pre-process, 23.6ms inference, 2.4ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/test_yolo_v5l_pretrained_v0.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ./yolov5/val.py --img 640 --task 'test' --weights runs/train/yolo_v5l_pretrained_v03.1/weights/best.pt --data ./yolov5/rip_detection.yaml --name test_yolo_v5l_pretrained_v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "biblical-procurement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=./yolov5/rip_detection.yaml, weights=['runs/train/yolo_v5l_custom_v0.1/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=test_yolo_v5l_custom_v0.1, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v5.0-351-ge96c74b torch 1.8.0a0+52ea372 CUDA:0 (Quadro P5000, 16278.5625MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 392 layers, 46600566 parameters, 0 gradients, 114.1 GFLOPs\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\u001b[34m\u001b[1mtest: \u001b[0mWARNING: Ignoring corrupted image and/or label datasets/images/test/rip-676.png: negative labels\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        162        162      0.897      0.864      0.927      0.383\n",
      "Speed: 0.2ms pre-process, 22.7ms inference, 2.1ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/test_yolo_v5l_custom_v0.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ./yolov5/val.py --img 640 --task 'test' --weights runs/train/yolo_v5l_custom_v0.1/weights/best.pt --data ./yolov5/rip_detection.yaml --name test_yolo_v5l_custom_v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "voluntary-founder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=./yolov5/rip_detection.yaml, weights=['runs/train/yolo_v5x_pretrained_v0.1/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=test_yolo_v5x_pretrained_v0.1, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v5.0-351-ge96c74b torch 1.8.0a0+52ea372 CUDA:0 (Quadro P5000, 16278.5625MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 476 layers, 87198694 parameters, 0 gradients, 217.1 GFLOPs\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\u001b[34m\u001b[1mtest: \u001b[0mWARNING: Ignoring corrupted image and/or label datasets/images/test/rip-676.png: negative labels\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        162        162      0.885      0.901      0.937       0.34\n",
      "Speed: 1.9ms pre-process, 41.0ms inference, 2.7ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/test_yolo_v5x_pretrained_v0.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ./yolov5/val.py --img 640 --task 'test' --weights runs/train/yolo_v5x_pretrained_v0.1/weights/best.pt --data ./yolov5/rip_detection.yaml --name test_yolo_v5x_pretrained_v0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "intensive-england",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=./yolov5/rip_detection.yaml, weights=['runs/train/yolo_v5x_custom_v0.1/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=test, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=test_yolo_v5x_custom_v0.1, exist_ok=False, half=False\n",
      "YOLOv5 ðŸš€ v5.0-351-ge96c74b torch 1.8.0a0+52ea372 CUDA:0 (Quadro P5000, 16278.5625MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 476 layers, 87198694 parameters, 0 gradients, 217.1 GFLOPs\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\u001b[34m\u001b[1mtest: \u001b[0mWARNING: Ignoring corrupted image and/or label datasets/images/test/rip-676.png: negative labels\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning 'datasets/labels/test.cache' images and labels... 163 found, 0 mi\u001b[0m\n",
      "               Class     Images     Labels          P          R     mAP@.5 mAP@\n",
      "                 all        162        162      0.931      0.926      0.951       0.38\n",
      "Speed: 1.5ms pre-process, 41.4ms inference, 2.8ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val/test_yolo_v5x_custom_v0.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python ./yolov5/val.py --img 640 --task 'test' --weights runs/train/yolo_v5x_custom_v0.1/weights/best.pt --data ./yolov5/rip_detection.yaml --name test_yolo_v5x_custom_v0.1 --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-motor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
